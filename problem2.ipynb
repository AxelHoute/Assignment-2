{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ZA-BzNiQieU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vXJ77tSwQieb"
      },
      "outputs": [],
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "# Let's load the TFLite model we saved to \"./saved_tflite_models/model_2.tflite\" above.\n",
        "model_complexity=0\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model_2.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDMlsJg8_7v5",
        "outputId": "62a7724e-b091-45b4-9ef0-7e539ccc24c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yR_QFyqEQied",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb76ffa3-6413-4ead-f917-810c98f255c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to ./gtsrb-german-traffic-sign\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 612M/612M [00:04<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "od.download('https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"gtsrb-german-traffic-sign/Test\",\n",
        "  labels=None,\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnPJBkTuAdPE",
        "outputId": "6796904a-89a9-48cf-b29e-f568a6882946"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12630 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "test = test.map(lambda x: (normalization_layer(x)))"
      ],
      "metadata": {
        "id": "eaM7Y0ZtAgkq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "output_data=[]\n",
        "for input_data in test:\n",
        "  input_data = np.float32(input_data)\n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "  # \"invoke()\" sends the data through the model.\n",
        "  interpreter.invoke()\n",
        "  output_data += [interpreter.get_tensor(output_details[0]['index'])]\n",
        "  #predicted_label_batch = class_names[output_data]\n",
        "time_prediction = time.time() - start_time\n",
        "print(time_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ITRNtr1AmhX",
        "outputId": "48eec5aa-77bb-432e-d418-ba0a77c02476"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "201.92879366874695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the time to make the prediction is way worst 80>201"
      ],
      "metadata": {
        "id": "aawjCE3TX9p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_data=np.argmax(output_data,axis=-1)"
      ],
      "metadata": {
        "id": "HQ9BF5F_K9J8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=pd.read_csv(\"gtsrb-german-traffic-sign/Test.csv\",sep=\",\")"
      ],
      "metadata": {
        "id": "8U2lhtMKAoOu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=0\n",
        "for n in range(len(output_data)):\n",
        "  if int(output_data[n][0])==int(results[\"ClassId\"][n]) and int(results[\"ClassId\"][n])<6:\n",
        "    acc+=1\n",
        "print(acc,len(results[results[\"ClassId\"].astype(int)<6][\"ClassId\"]), acc*100/len(results[results[\"ClassId\"]<10][\"ClassId\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKfRqJ7VAx3u",
        "outputId": "e74919cd-188b-4519-9e21-f26fe3db1689"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339 3270 7.0625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have better accuracy on this model"
      ],
      "metadata": {
        "id": "2Umx26nkVoIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"model_size_compressed =\",os.path.getsize('model_2.tflite'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu2dxCOFNYRH",
        "outputId": "b21751bd-2def-4af3-c095-add91dd64bed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_size_compressed = 8916092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.9MB of size, which is evier than the orther one"
      ],
      "metadata": {
        "id": "SlWYRBhYVrs5"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}