{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkhIM2P07k7n",
        "outputId": "9fabc17f-3dd8-4773-d362-bce1ac2e1458"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pfL2B7oWUT2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "od.download('https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoOdYkoV7wvv",
        "outputId": "4de41213-3cd3-4228-db0d-c924dcf437a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to ./gtsrb-german-traffic-sign\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 612M/612M [00:07<00:00, 84.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vjwg4fgm2ap7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import PIL.Image as Image\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub # pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKz8jabp2aqC",
        "outputId": "d1ccb9e1-ad44-4669-bba8-68db29d3362d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14670 files belonging to 10 classes.\n",
            "Using 11736 files for training.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 60\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"gtsrb-german-traffic-sign/Train-1\",\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  label_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"gtsrb-german-traffic-sign/Train-1\",\n",
        "    validation_split=0.2,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=10,\n",
        "      seed=123,\n",
        "    subset=\"validation\",\n",
        "    label_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wrUjDFtTpiO",
        "outputId": "d82eff95-f899-4426-9c34-fed92f890604"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14670 files belonging to 10 classes.\n",
            "Using 2934 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Kr29iMbT2aqB"
      },
      "outputs": [],
      "source": [
        "keras_cache_dir = os.path.join(os.getcwd(),'keras_cache')\n",
        "os.makedirs(keras_cache_dir, exist_ok = True)\n",
        "\n",
        "# Note: The Keras home directory is hard-coded to\n",
        "# \"~/.keras\" (Linux) or \"%USERPROFILE%\\.keras\" on Windows\n",
        "# so any weights downloaded from \"keras.applications\" will\n",
        "# be found there (in the subdirectory \"models\").\n",
        "\n",
        "tfhub_cache_dir = os.path.join(os.getcwd(),'tfhub_cache')\n",
        "os.makedirs(tfhub_cache_dir, exist_ok = True)\n",
        "os.environ['TFHUB_CACHE_DIR'] = tfhub_cache_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BW5ccocbSJ2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vR2kIpGS2aqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d0ed76-8816-4344-e7d1-d7d5e3c88432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
          ]
        }
      ],
      "source": [
        "class_names = np.array(train_ds.class_names)\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3uJZjqUa2aqE"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFQTxaEn2aqF"
      },
      "source": [
        "After the import part, we're gonna train our new model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dDld0PDT2aqH"
      },
      "outputs": [],
      "source": [
        "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Ih523ymX2aqI"
      },
      "outputs": [],
      "source": [
        "feature_extractor_layer = hub.KerasLayer(\n",
        "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRMgpwns2aqK",
        "outputId": "11330b9c-090c-47f5-c878-bef1f00f930c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2270794 (8.66 MB)\n",
            "Trainable params: 12810 (50.04 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the size of the model is 8.66MB\n"
      ],
      "metadata": {
        "id": "JlEfRpvVVaP7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "6VKkYGrw2aqL"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZo_Lp7j2aqM",
        "outputId": "47d16577-191e-42fe-d003-dea376c89400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 30s 116ms/step - loss: 1.0819 - acc: 0.6449 - val_loss: 2.6206 - val_acc: 0.1517\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 17s 89ms/step - loss: 0.6026 - acc: 0.8205 - val_loss: 2.7606 - val_acc: 0.1527\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "tensorboard_logdir = os.path.join(os.getcwd(),'logs','tensorboard') # Let's log Tensorboard data to this folder\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=tensorboard_logdir) # Create a Tensorboard \"callback\"\n",
        "history = model.fit(train_ds, epochs=5,validation_data=validation_data,\n",
        "                    callbacks=[tensorboard_callback,tf.keras.callbacks.EarlyStopping(patience=1)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2S1nH1Z2aqQ"
      },
      "source": [
        "My new model works perfectly, we can verify it with th graph of accuracy but also with the response in the images. Know we're gonna save it for the problem 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_layer.trainable = True\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['acc'])\n",
        "model.fit(train_ds, epochs=5,validation_data=validation_data,\n",
        "                    callbacks=[tensorboard_callback,tf.keras.callbacks.EarlyStopping(patience=0)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igMWOWbfyijW",
        "outputId": "17bbdc84-0753-48b0-81ae-db44dd471868"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 80s 277ms/step - loss: 1.2190 - acc: 0.6231 - val_loss: 3.4960 - val_acc: 0.0845\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 52s 266ms/step - loss: 0.5419 - acc: 0.8592 - val_loss: 3.7579 - val_acc: 0.0842\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a68ca101ae0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"gtsrb-german-traffic-sign/Test\",\n",
        "  labels=None,\n",
        "  seed=123,\n",
        "  label_mode='categorical',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tRwVW9uVyyp",
        "outputId": "2df0f045-3d88-4653-b7c5-f15f4b90426f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12630 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "test = test.map(lambda x: (normalization_layer(x)))\n",
        "#AUTOTUNE = tf.data.AUTOTUNE\n",
        "#test = test.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "8rBXXvCZwf1m"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "predicted_batch = model.predict(test)\n",
        "time_prediction = (time.time() - start_time)\n",
        "print(int(time_prediction))\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uesC4ux0XE7t",
        "outputId": "d80c31a7-2bb3-4111-dd19-ba608f4c6d3d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12630/12630 [==============================] - 76s 6ms/step\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "80 seconds to predict"
      ],
      "metadata": {
        "id": "8MrGZAV3Vh6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results=pd.read_csv(\"gtsrb-german-traffic-sign/Test.csv\",sep=\",\")"
      ],
      "metadata": {
        "id": "fSItW0CdZdHP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc=0\n",
        "for n in range(len(predicted_label_batch)):\n",
        "  if int(predicted_label_batch[n].title())==int(results[\"ClassId\"][n]) and int(results[\"ClassId\"][n])<6:\n",
        "    acc+=1\n",
        "print(acc,len(results[results[\"ClassId\"].astype(int)<6][\"ClassId\"]), acc*100/len(results[results[\"ClassId\"]<10][\"ClassId\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcnCy6Npl1bk",
        "outputId": "6d7f3671-97f5-4196-cc3d-ea48bd4eb253"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "326 3270 6.791666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flatbuffers\n",
        "# Convert the model (note: we are converting the model directly from the \"model\" variable)\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "print(1)\n",
        "# Let's save the model as \"model_2.tflite\"\n",
        "tflite_model2_path = os.path.join(os.getcwd(),'model_2.tflite')\n",
        "with open(tflite_model2_path, 'wb') as f:\n",
        "  f.write(tflite_model)\n"
      ],
      "metadata": {
        "id": "55ji9KlUluXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ee4f75-e25d-433a-b059-57584323333a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}